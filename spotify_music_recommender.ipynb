{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevant imports and initialization code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "seed = 25\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section reads in our data from our Spotify track dataset. This dataset has a large amount of data that's captured per track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "12\n",
      "2\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3.535000e+03</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>35.586421</td>\n",
       "      <td>0.408049</td>\n",
       "      <td>0.537186</td>\n",
       "      <td>2.346535e+05</td>\n",
       "      <td>0.557125</td>\n",
       "      <td>0.178248</td>\n",
       "      <td>0.224884</td>\n",
       "      <td>-10.167798</td>\n",
       "      <td>0.131284</td>\n",
       "      <td>116.940285</td>\n",
       "      <td>0.453908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.704144</td>\n",
       "      <td>0.369598</td>\n",
       "      <td>0.193352</td>\n",
       "      <td>1.346670e+05</td>\n",
       "      <td>0.279653</td>\n",
       "      <td>0.326769</td>\n",
       "      <td>0.211943</td>\n",
       "      <td>6.397070</td>\n",
       "      <td>0.209738</td>\n",
       "      <td>31.297850</td>\n",
       "      <td>0.268361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>3.405300e+04</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>-47.046000</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>37.934000</td>\n",
       "      <td>0.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.045800</td>\n",
       "      <td>0.403000</td>\n",
       "      <td>1.745980e+05</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097300</td>\n",
       "      <td>-12.983500</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>91.846000</td>\n",
       "      <td>0.218000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.556000</td>\n",
       "      <td>2.169330e+05</td>\n",
       "      <td>0.597000</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.131000</td>\n",
       "      <td>-8.133000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>115.056000</td>\n",
       "      <td>0.447000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.804000</td>\n",
       "      <td>0.683000</td>\n",
       "      <td>2.663330e+05</td>\n",
       "      <td>0.793000</td>\n",
       "      <td>0.122000</td>\n",
       "      <td>0.272000</td>\n",
       "      <td>-5.655000</td>\n",
       "      <td>0.106500</td>\n",
       "      <td>138.030500</td>\n",
       "      <td>0.673000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>91.000000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.954000</td>\n",
       "      <td>3.059427e+06</td>\n",
       "      <td>0.998000</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>-0.366000</td>\n",
       "      <td>0.964000</td>\n",
       "      <td>220.119000</td>\n",
       "      <td>0.989000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        popularity  acousticness  danceability   duration_ms       energy  \\\n",
       "count  3535.000000   3535.000000   3535.000000  3.535000e+03  3535.000000   \n",
       "mean     35.586421      0.408049      0.537186  2.346535e+05     0.557125   \n",
       "std      17.704144      0.369598      0.193352  1.346670e+05     0.279653   \n",
       "min       0.000000      0.000003      0.057000  3.405300e+04     0.001250   \n",
       "25%      24.000000      0.045800      0.403000  1.745980e+05     0.330000   \n",
       "50%      36.000000      0.278000      0.556000  2.169330e+05     0.597000   \n",
       "75%      48.000000      0.804000      0.683000  2.663330e+05     0.793000   \n",
       "max      91.000000      0.996000      0.954000  3.059427e+06     0.998000   \n",
       "\n",
       "       instrumentalness     liveness     loudness  speechiness        tempo  \\\n",
       "count       3535.000000  3535.000000  3535.000000  3535.000000  3535.000000   \n",
       "mean           0.178248     0.224884   -10.167798     0.131284   116.940285   \n",
       "std            0.326769     0.211943     6.397070     0.209738    31.297850   \n",
       "min            0.000000     0.011900   -47.046000     0.022800    37.934000   \n",
       "25%            0.000000     0.097300   -12.983500     0.036900    91.846000   \n",
       "50%            0.000067     0.131000    -8.133000     0.050000   115.056000   \n",
       "75%            0.122000     0.272000    -5.655000     0.106500   138.030500   \n",
       "max            0.985000     0.996000    -0.366000     0.964000   220.119000   \n",
       "\n",
       "           valence  \n",
       "count  3535.000000  \n",
       "mean      0.453908  \n",
       "std       0.268361  \n",
       "min       0.022500  \n",
       "25%       0.218000  \n",
       "50%       0.447000  \n",
       "75%       0.673000  \n",
       "max       0.989000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/spotify_songs.csv')\n",
    "# we only want a certain number of columns. Reducing unneeded features will improve performance.\n",
    "df = df[['genre','artist_name','track_id','popularity','acousticness','danceability','duration_ms','energy','instrumentalness','key','liveness','loudness','mode','speechiness','tempo','time_signature','valence']]\n",
    "df.drop_duplicates('track_id', inplace=True)\n",
    "df = df.sample(frac=0.02, random_state=seed)\n",
    "\n",
    "print(len(df['genre'].unique()))\n",
    "print(len(df['key'].unique()))\n",
    "print(len(df['mode'].unique()))\n",
    "print(len(df['time_signature'].unique()))\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read in our other dataset that contains user created playlist with songs with them. This will be crucial to generating a desired y label that we will want our neural network to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_df = pd.read_json('./datasets/challenge_set.json')\n",
    "playlist_series = playlist_df['playlists']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the code before does not output any information about the genre or track id. This is because in the dataset they are string values.\n",
    "\n",
    "This code section rearranges the dataset to be more compatible with machine learning. One aspect of this is converting unique string values into a numeric equivalent. The Tensorflow normalization layer will handle proper normalization after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3.535000e+03</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "      <td>3535.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.971429</td>\n",
       "      <td>912.655446</td>\n",
       "      <td>1767.000000</td>\n",
       "      <td>35.586421</td>\n",
       "      <td>0.408049</td>\n",
       "      <td>0.537186</td>\n",
       "      <td>2.346535e+05</td>\n",
       "      <td>0.557125</td>\n",
       "      <td>0.178248</td>\n",
       "      <td>5.695615</td>\n",
       "      <td>0.224884</td>\n",
       "      <td>-10.167798</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.131284</td>\n",
       "      <td>116.940285</td>\n",
       "      <td>0.950778</td>\n",
       "      <td>0.453908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.098429</td>\n",
       "      <td>651.637088</td>\n",
       "      <td>1020.610928</td>\n",
       "      <td>17.704144</td>\n",
       "      <td>0.369598</td>\n",
       "      <td>0.193352</td>\n",
       "      <td>1.346670e+05</td>\n",
       "      <td>0.279653</td>\n",
       "      <td>0.326769</td>\n",
       "      <td>3.736454</td>\n",
       "      <td>0.211943</td>\n",
       "      <td>6.397070</td>\n",
       "      <td>0.474731</td>\n",
       "      <td>0.209738</td>\n",
       "      <td>31.297850</td>\n",
       "      <td>0.496574</td>\n",
       "      <td>0.268361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>3.405300e+04</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>-47.046000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>37.934000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>883.500000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.045800</td>\n",
       "      <td>0.403000</td>\n",
       "      <td>1.745980e+05</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.097300</td>\n",
       "      <td>-12.983500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036900</td>\n",
       "      <td>91.846000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.218000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>811.000000</td>\n",
       "      <td>1767.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.556000</td>\n",
       "      <td>2.169330e+05</td>\n",
       "      <td>0.597000</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.131000</td>\n",
       "      <td>-8.133000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>115.056000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.447000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>1448.500000</td>\n",
       "      <td>2650.500000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.804000</td>\n",
       "      <td>0.683000</td>\n",
       "      <td>2.663330e+05</td>\n",
       "      <td>0.793000</td>\n",
       "      <td>0.122000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.272000</td>\n",
       "      <td>-5.655000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.106500</td>\n",
       "      <td>138.030500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.673000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>2233.000000</td>\n",
       "      <td>3534.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.954000</td>\n",
       "      <td>3.059427e+06</td>\n",
       "      <td>0.998000</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>-0.366000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964000</td>\n",
       "      <td>220.119000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.989000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             genre  artist_name     track_id   popularity  acousticness  \\\n",
       "count  3535.000000  3535.000000  3535.000000  3535.000000   3535.000000   \n",
       "mean     10.971429   912.655446  1767.000000    35.586421      0.408049   \n",
       "std       7.098429   651.637088  1020.610928    17.704144      0.369598   \n",
       "min       0.000000     0.000000     0.000000     0.000000      0.000003   \n",
       "25%       5.000000   332.000000   883.500000    24.000000      0.045800   \n",
       "50%      10.000000   811.000000  1767.000000    36.000000      0.278000   \n",
       "75%      16.000000  1448.500000  2650.500000    48.000000      0.804000   \n",
       "max      26.000000  2233.000000  3534.000000    91.000000      0.996000   \n",
       "\n",
       "       danceability   duration_ms       energy  instrumentalness          key  \\\n",
       "count   3535.000000  3.535000e+03  3535.000000       3535.000000  3535.000000   \n",
       "mean       0.537186  2.346535e+05     0.557125          0.178248     5.695615   \n",
       "std        0.193352  1.346670e+05     0.279653          0.326769     3.736454   \n",
       "min        0.057000  3.405300e+04     0.001250          0.000000     0.000000   \n",
       "25%        0.403000  1.745980e+05     0.330000          0.000000     2.000000   \n",
       "50%        0.556000  2.169330e+05     0.597000          0.000067     6.000000   \n",
       "75%        0.683000  2.663330e+05     0.793000          0.122000     9.000000   \n",
       "max        0.954000  3.059427e+06     0.998000          0.985000    11.000000   \n",
       "\n",
       "          liveness     loudness         mode  speechiness        tempo  \\\n",
       "count  3535.000000  3535.000000  3535.000000  3535.000000  3535.000000   \n",
       "mean      0.224884   -10.167798     0.342857     0.131284   116.940285   \n",
       "std       0.211943     6.397070     0.474731     0.209738    31.297850   \n",
       "min       0.011900   -47.046000     0.000000     0.022800    37.934000   \n",
       "25%       0.097300   -12.983500     0.000000     0.036900    91.846000   \n",
       "50%       0.131000    -8.133000     0.000000     0.050000   115.056000   \n",
       "75%       0.272000    -5.655000     1.000000     0.106500   138.030500   \n",
       "max       0.996000    -0.366000     1.000000     0.964000   220.119000   \n",
       "\n",
       "       time_signature      valence  \n",
       "count     3535.000000  3535.000000  \n",
       "mean         0.950778     0.453908  \n",
       "std          0.496574     0.268361  \n",
       "min          0.000000     0.022500  \n",
       "25%          1.000000     0.218000  \n",
       "50%          1.000000     0.447000  \n",
       "75%          1.000000     0.673000  \n",
       "max          3.000000     0.989000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_values(col):\n",
    "    unique_items = col.unique().tolist()\n",
    "    items_to_encoded = {x: i for i, x in enumerate(unique_items)}\n",
    "    encoded_to_items = {i: x for i, x in enumerate(unique_items)}\n",
    "    return (items_to_encoded, encoded_to_items)\n",
    "\n",
    "genre_items_to_encoded, genre_encoded_to_items = encode_values(df['genre'])\n",
    "df['genre'] = df['genre'].map(genre_items_to_encoded)\n",
    "\n",
    "artist_name_items_to_encoded, artist_name_encoded_to_items = encode_values(df['artist_name'])\n",
    "df['artist_name'] = df['artist_name'].map(artist_name_items_to_encoded)\n",
    "\n",
    "track_id_items_to_encoded, track_id_encoded_to_items = encode_values(df['track_id'])\n",
    "df['track_id'] = df['track_id'].map(track_id_items_to_encoded)\n",
    "\n",
    "key_items_to_encoded, key_encoded_to_items = encode_values(df['key'])\n",
    "df['key'] = df['key'].map(key_items_to_encoded)\n",
    "\n",
    "mode_items_to_encoded, mode_encoded_to_items = encode_values(df['mode'])\n",
    "df['mode'] = df['mode'].map(mode_items_to_encoded)\n",
    "\n",
    "time_signature_items_to_encoded, time_signature_encoded_to_items = encode_values(df['time_signature'])\n",
    "df['time_signature'] = df['time_signature'].map(time_signature_items_to_encoded)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we build a pseudo histogram where we capture the frequency in which a particular song is in a playlist with another song. In training, this will generate the y label based on how frequent a song is found with another one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = int(0.9 * df.shape[0])\n",
    "train_df = df.iloc[:train_indices]\n",
    "train_track_id_items_to_encoded = {key: value for key, value in list(track_id_items_to_encoded.items())[:train_indices]}\n",
    "\n",
    "encoded_track_histogram = {int(row['track_id']): set() for index, row in train_df.iterrows()}\n",
    "for playlist in playlist_series:\n",
    "    playlist_tracks = [track['track_uri'].split(':')[2] for track in playlist['tracks']]\n",
    "    included_tracks = [track for track in playlist_tracks if track in train_track_id_items_to_encoded]\n",
    "    encoded_tracks = [train_track_id_items_to_encoded[track] for track in included_tracks]\n",
    "    \n",
    "    if (len(encoded_tracks) > 1):\n",
    "        for x in encoded_tracks:\n",
    "            for y in encoded_tracks:\n",
    "                encoded_track_histogram[x].add(y)\n",
    "\n",
    "x_data = df.values.astype(np.float32)\n",
    "y_data = []\n",
    "\n",
    "for index, row in train_df.iterrows():\n",
    "    probability = np.zeros(len(encoded_track_histogram))\n",
    "    histogram_data = encoded_track_histogram[row['track_id']]\n",
    "    for histogram_datapoint in histogram_data:\n",
    "        probability[histogram_datapoint] = probability[histogram_datapoint] + (1 / len(histogram_data))\n",
    "    y_data.append(probability)\n",
    "\n",
    "x_train = x_data[:train_indices]\n",
    "x_test = x_data[train_indices:]\n",
    "y_train = np.array(y_data)[:train_indices]\n",
    "y_test = np.array(y_data)[train_indices:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section builds the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model(features, num_classes):\n",
    "    normal_layer = tf.keras.layers.Normalization(axis=-1)\n",
    "    normal_layer.adapt(features)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "      normal_layer,\n",
    "      keras.layers.Dense(64, activation='relu'),\n",
    "      keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3181, 17)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_3 (Normaliza  (None, 17)                35        \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                1152      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3181)              206765    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 207952 (812.32 KB)\n",
      "Trainable params: 207917 (812.18 KB)\n",
      "Non-trainable params: 35 (144.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "16/16 - 0s - loss: 0.6333 - accuracy: 3.1437e-04 - 325ms/epoch - 20ms/step\n",
      "Epoch 2/20\n",
      "16/16 - 0s - loss: 0.6096 - accuracy: 9.4310e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 3/20\n",
      "16/16 - 0s - loss: 0.5808 - accuracy: 0.0016 - 65ms/epoch - 4ms/step\n",
      "Epoch 4/20\n",
      "16/16 - 0s - loss: 0.5470 - accuracy: 0.0000e+00 - 67ms/epoch - 4ms/step\n",
      "Epoch 5/20\n",
      "16/16 - 0s - loss: 0.5116 - accuracy: 9.4310e-04 - 67ms/epoch - 4ms/step\n",
      "Epoch 6/20\n",
      "16/16 - 0s - loss: 0.4821 - accuracy: 9.4310e-04 - 66ms/epoch - 4ms/step\n",
      "Epoch 7/20\n",
      "16/16 - 0s - loss: 0.4594 - accuracy: 0.0016 - 66ms/epoch - 4ms/step\n",
      "Epoch 8/20\n",
      "16/16 - 0s - loss: 0.4427 - accuracy: 0.0028 - 67ms/epoch - 4ms/step\n",
      "Epoch 9/20\n",
      "16/16 - 0s - loss: 0.4299 - accuracy: 0.0044 - 67ms/epoch - 4ms/step\n",
      "Epoch 10/20\n",
      "16/16 - 0s - loss: 0.4193 - accuracy: 0.0060 - 68ms/epoch - 4ms/step\n",
      "Epoch 11/20\n",
      "16/16 - 0s - loss: 0.4104 - accuracy: 0.0079 - 73ms/epoch - 5ms/step\n",
      "Epoch 12/20\n",
      "16/16 - 0s - loss: 0.4033 - accuracy: 0.0085 - 69ms/epoch - 4ms/step\n",
      "Epoch 13/20\n",
      "16/16 - 0s - loss: 0.3970 - accuracy: 0.0101 - 70ms/epoch - 4ms/step\n",
      "Epoch 14/20\n",
      "16/16 - 0s - loss: 0.3916 - accuracy: 0.0113 - 71ms/epoch - 4ms/step\n",
      "Epoch 15/20\n",
      "16/16 - 0s - loss: 0.3867 - accuracy: 0.0123 - 69ms/epoch - 4ms/step\n",
      "Epoch 16/20\n",
      "16/16 - 0s - loss: 0.3824 - accuracy: 0.0116 - 69ms/epoch - 4ms/step\n",
      "Epoch 17/20\n",
      "16/16 - 0s - loss: 0.3783 - accuracy: 0.0123 - 72ms/epoch - 5ms/step\n",
      "Epoch 18/20\n",
      "16/16 - 0s - loss: 0.3745 - accuracy: 0.0132 - 68ms/epoch - 4ms/step\n",
      "Epoch 19/20\n",
      "16/16 - 0s - loss: 0.3715 - accuracy: 0.0135 - 71ms/epoch - 4ms/step\n",
      "Epoch 20/20\n",
      "16/16 - 0s - loss: 0.3687 - accuracy: 0.0145 - 68ms/epoch - 4ms/step\n",
      "(3181, 17)\n",
      "(3181, 17)\n",
      "(354, 17)\n",
      "(0, 3181)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 354\n  y sizes: 0\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19920\\1856304887.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\itsda\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\itsda\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1958\u001b[0m             )\n\u001b[0;32m   1959\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1962\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 354\n  y sizes: 0\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "from numpy import savetxt\n",
    "savetxt('data.npy', x_train)\n",
    "model = build_and_compile_model(x_train, len(x_train))\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=200, verbose=2) #  validation_data=(x_test, y_test)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
